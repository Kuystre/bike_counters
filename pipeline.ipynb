{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8bc384e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "effae9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _encode_dates(X):\n",
    "    \n",
    "    X = X.copy()  \n",
    "    X.loc[:, \"year\"] = X[\"date\"].dt.year\n",
    "    X.loc[:, \"month\"] = X[\"date\"].dt.month\n",
    "    X.loc[:, \"day\"] = X[\"date\"].dt.day\n",
    "    X.loc[:, \"weekday\"] = X[\"date\"].dt.weekday\n",
    "    X.loc[:, \"hour\"] = X[\"date\"].dt.hour\n",
    "\n",
    "    return X.drop(columns=[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6a4051ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _merge_external_data(X):\n",
    "    df_ext = pd.read_csv(\"/kaggle/input/mdsb-2023/external_data.csv\", parse_dates=[\"date\"])\n",
    "\n",
    "    X = X.copy()\n",
    "    \n",
    "    # Keeping the original index to sort back afterwards\n",
    "    X[\"orig_index\"] = np.arange(X.shape[0])\n",
    "    X = pd.merge_asof(\n",
    "        X.sort_values(\"date\"), df_ext[[\"date\", \"ww\", \"u\", \"etat_sol\"]].sort_values(\"date\"), on=\"date\" # Chosen weather-related features\n",
    "    )\n",
    "    # Sort back to the original order\n",
    "    X = X.sort_values(\"orig_index\")\n",
    "    del X[\"orig_index\"]\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cdf306cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from workalendar.europe import France\n",
    "\n",
    "def add_new_features(df):\n",
    "    # Create an instance of the France calendar \n",
    "    cal = France()\n",
    "\n",
    "    # Convert 'date' to datetime\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "    # Adding relevant date-related features\n",
    "    df['is_weekend'] = df['date'].dt.weekday.isin([5, 6]).astype(int)\n",
    "    df['is_holiday'] = df['date'].apply(lambda x: cal.is_holiday(x)).astype(int)\n",
    "        \n",
    "    # Adding curfew periods\n",
    "    curfew_periods = [\n",
    "        (pd.to_datetime(\"2020-10-17\"), pd.to_datetime(\"2020-12-15\"), 21, 6),\n",
    "        (pd.to_datetime(\"2020-12-15\"), pd.to_datetime(\"2021-01-16\"), 20, 6),\n",
    "        (pd.to_datetime(\"2021-01-16\"), pd.to_datetime(\"2021-05-19\"), 18, 6),\n",
    "        (pd.to_datetime(\"2021-05-19\"), pd.to_datetime(\"2021-06-09\"), 21, 6),\n",
    "        (pd.to_datetime(\"2021-06-09\"), pd.to_datetime(\"2021-06-30\"), 23, 6)\n",
    "    ]\n",
    "\n",
    "    # Function to check if a datetime is within the curfew period\n",
    "    def is_curfew(date):\n",
    "        hour = date.hour\n",
    "        for start, end, start_hour, end_hour in curfew_periods:\n",
    "            if start <= date <= end:\n",
    "                if start_hour <= hour or hour < end_hour:  # Curfew hours\n",
    "                    return 1\n",
    "        return 0\n",
    "\n",
    "    # Apply the function to each row\n",
    "    df['is_curfew'] = df['date'].apply(is_curfew)\n",
    "     \n",
    "    # Adding cyclic encoding for day, month, and hour\n",
    "    df['day_sin'] = np.sin(2 * np.pi * df['date'].dt.day / df['date'].dt.days_in_month)\n",
    "    df['day_cos'] = np.cos(2 * np.pi * df['date'].dt.day / df['date'].dt.days_in_month)\n",
    "    df['month_sin'] = np.sin(2 * np.pi * df['date'].dt.month / 12)\n",
    "    df['month_cos'] = np.cos(2 * np.pi * df['date'].dt.month / 12)\n",
    "    df['hour_sin'] = np.sin(2 * np.pi * df['date'].dt.hour / 24)\n",
    "    df['hour_cos'] = np.cos(2 * np.pi * df['date'].dt.hour / 24)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fdf6a881",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline():\n",
    "\n",
    "    # Pipeline components\n",
    "    date_encoder = FunctionTransformer(_encode_dates)\n",
    "    date_cols = [\"year\", \"month\", \"day\", \"weekday\", \"hour\"]\n",
    "\n",
    "    # Relevant features selected\n",
    "    categorical_cols = [\n",
    "        \"counter_name\", \"site_name\", \"etat_sol\", \"ww\", \n",
    "        \"is_weekend\", \"is_holiday\", \"is_curfew\"]\n",
    "    numerical_cols = [\"u\", \"day_sin\", \"day_cos\", \"month_sin\", \"month_cos\", \"hour_sin\", \"hour_cos\"]\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        [\n",
    "            (\"date\", OneHotEncoder(handle_unknown=\"ignore\"), date_cols),\n",
    "            (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_cols),\n",
    "            (\"num\", 'passthrough', numerical_cols) \n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # XGB Regressor parameters\n",
    "    regressor = xgb.XGBRegressor(max_depth=8, objective='reg:squarederror', learning_rate=0.2, n_estimators=100)\n",
    "\n",
    "    # Final pipeline\n",
    "    pipe = make_pipeline(\n",
    "        FunctionTransformer(add_new_features, validate=False),\n",
    "        FunctionTransformer(_merge_external_data, validate=False),\n",
    "        date_encoder,\n",
    "        preprocessor,\n",
    "        regressor\n",
    "    )\n",
    "\n",
    "    return pipe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "33f0b1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_parquet(\"train.parquet\")\n",
    "data_test = pd.read_parquet(\"test.parquet\")\n",
    "\n",
    "data = pd.concat((data_train, data_test))\n",
    "\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "\n",
    "# Filter out the data that falls within the lockdown period\n",
    "lockdown_start = pd.to_datetime(\"2020-10-30\")\n",
    "lockdown_end = pd.to_datetime(\"2020-12-15\")\n",
    "data = data[~((data['date'] >= lockdown_start) & (data['date'] <= lockdown_end))]\n",
    "\n",
    "X = data.drop([\"bike_count\", \"log_bike_count\"], axis=1)\n",
    "y = data[\"log_bike_count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0a70027c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = create_pipeline()\n",
    "pipe.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b55254f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final_test = pd.read_parquet(\"final_test.parquet\")\n",
    "y_pred = pipe.predict(X_final_test)\n",
    "\n",
    "# Replacing negative values by 0 (log(1+x) is always positive)\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i] < 0:\n",
    "        y_pred[i] = 0\n",
    "\n",
    "results = pd.DataFrame(\n",
    "    dict(\n",
    "        Id=np.arange(y_pred.shape[0]),\n",
    "        log_bike_count=y_pred,\n",
    "    )\n",
    ")\n",
    "results.to_csv(\"submission_XGB_curfew.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
